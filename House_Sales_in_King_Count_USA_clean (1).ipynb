{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Sales in King County, USA\n\nPredicting house prices using exploratory data analysis and regression models.\n\nThis is a cleaned, portfolio-ready version of the original IBM project notebook. It focuses on your analysis and code, and removes platform-specific boilerplate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset\n\nThis notebook uses the **King County house sales dataset** with missing values (`kc_house_data_NaN.csv`).\n\n- Original source (IBM Developer Skills Network):  \n  `kc_house_data_NaN.csv` from the course *Data Analysis with Python*  \n- Direct download URL:  \n  `https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/FinalModule_Coursera/data/kc_house_data_NaN.csv`\n\nTo make the notebook easy to run for anyone:\n\n1. You can either **download the CSV manually** and place it in a local `data/` folder, or\n2. Let the notebook **download it automatically** from the URL if the local file is not found.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup\n\nImport the libraries used throughout the analysis and configure the environment."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Suppress non-critical warnings (optional)\nimport warnings\ndef warn(*args, **kwargs):\n    pass\nwarnings.warn = warn\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import r2_score, mean_squared_error\n\n%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data loading and initial inspection\n\nThe code below:\n\n1. Defines the direct **online URL** of the dataset\n2. Looks for a local copy at `data/kc_house_data_NaN.csv`\n3. If the local file is missing, it loads the data **directly from the URL**\n\nThis way, anyone cloning the repository can run the notebook as long as they have an internet connection or have placed the CSV into the `data/` folder."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "DATA_URL = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/FinalModule_Coursera/data/kc_house_data_NaN.csv\"\nDATA_DIR = \"data\"\nDATA_PATH = os.path.join(DATA_DIR, \"kc_house_data_NaN.csv\")\n\n# Create data directory if it doesn't exist\nos.makedirs(DATA_DIR, exist_ok=True)\n\nif os.path.exists(DATA_PATH):\n    print(f\"Loading data from local file: {DATA_PATH}\")\n    df = pd.read_csv(DATA_PATH)\nelse:\n    print(\"Local file not found. Loading data from URL...\")\n    print(f\"URL: {DATA_URL}\")\n    df = pd.read_csv(DATA_URL)\n    # Optionally save a local copy for future runs\n    df.to_csv(DATA_PATH, index=False)\n    print(f\"Dataset downloaded and saved to: {DATA_PATH}\")\n\nprint(\"Data shape:\", df.shape)\ndf.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Structure and summary statistics\n\nInspect column types and basic descriptive statistics to understand the dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info()\ndf.describe().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data wrangling\n\nWe remove identifier columns that are not useful for prediction and handle missing values in key numerical features."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Drop identifier columns that do not carry predictive information\nfor col in [\"id\", \"Unnamed: 0\"]:\n    if col in df.columns:\n        df.drop(col, axis=1, inplace=True)\n\n# Check missing values in bedrooms and bathrooms\nprint(\"Missing bedrooms before:\", df['bedrooms'].isnull().sum())\nprint(\"Missing bathrooms before:\", df['bathrooms'].isnull().sum())\n\n# Impute with the mean\ndf['bedrooms'].fillna(df['bedrooms'].mean(), inplace=True)\ndf['bathrooms'].fillna(df['bathrooms'].mean(), inplace=True)\n\nprint(\"Missing bedrooms after:\", df['bedrooms'].isnull().sum())\nprint(\"Missing bathrooms after:\", df['bathrooms'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exploratory data analysis (EDA)\n\nWe explore the distribution of key variables and their relationships with the target variable `price`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Distribution of the number of floors\nfloors_counts = df['floors'].value_counts().to_frame(name='count')\nfloors_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Price distribution by waterfront vs. non-waterfront properties\nsns.boxplot(x='waterfront', y='price', data=df)\nplt.title(\"House price distribution by waterfront\")\nplt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Relationship between above-ground square footage and price\nsns.regplot(x='sqft_above', y='price', data=df)\nplt.title(\"sqft_above vs price\")\nplt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Correlation of numerical features with price\ncorr_with_price = df.corr(numeric_only=True)['price'].sort_values(ascending=False)\ncorr_with_price\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model development\n\nWe start with a simple linear regression model, then move to a multivariate model using several predictive features."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Simple linear regression using sqft_living as the only predictor\nlm_simple = LinearRegression()\n\nX_simple = df[['sqft_living']]\ny = df['price']\n\nlm_simple.fit(X_simple, y)\nr2_simple = lm_simple.score(X_simple, y)\nprint(f\"R^2 (simple model with sqft_living): {r2_simple:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Multivariate linear regression with a richer set of features\nfeatures = [\n    \"floors\",\n    \"waterfront\",\n    \"lat\",\n    \"bedrooms\",\n    \"sqft_basement\",\n    \"view\",\n    \"bathrooms\",\n    \"sqft_living15\",\n    \"sqft_above\",\n    \"grade\",\n    \"sqft_living\",\n]\n\n# Keep only features that actually exist in the dataframe\nfeatures = [f for f in features if f in df.columns]\n\nX = df[features]\ny = df['price']\n\nlm_multi = LinearRegression()\nlm_multi.fit(X, y)\n\nr2_multi = lm_multi.score(X, y)\nprint(\"Features used:\", features)\nprint(f\"R^2 (multivariate model): {r2_multi:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Pipeline: scaling + polynomial features + linear regression\npoly_pipeline = Pipeline([\n    (\"scale\", StandardScaler()),\n    (\"poly\", PolynomialFeatures(degree=2, include_bias=False)),\n    (\"model\", LinearRegression()),\n])\n\ncv_scores = cross_val_score(poly_pipeline, X, y, cv=5, scoring=\"r2\")\nprint(\"Cross-validated R^2 (polynomial pipeline):\")\nprint(\"Scores:\", cv_scores)\nprint(\"Mean R^2:\", cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model evaluation and refinement\n\nWe evaluate the model using a train/test split and experiment with a Ridge regression model, with and without polynomial features."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train/test split\nx_train, x_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.15, random_state=1\n)\n\nprint(\"Number of training samples:\", x_train.shape[0])\nprint(\"Number of test samples:\", x_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Ridge regression on the original feature space\nridge = Ridge(alpha=0.1)\nridge.fit(x_train, y_train)\n\ny_test_pred = ridge.predict(x_test)\n\nr2_ridge = r2_score(y_test, y_test_pred)\nrmse_ridge = mean_squared_error(y_test, y_test_pred, squared=False)\n\nprint(f\"R^2 (Ridge, test set): {r2_ridge:.3f}\")\nprint(f\"RMSE (Ridge, test set): {rmse_ridge:,.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Ridge regression with polynomial features\npoly = PolynomialFeatures(degree=2, include_bias=False)\n\nx_train_pr = poly.fit_transform(x_train)\nx_test_pr = poly.transform(x_test)\n\nridge_poly = Ridge(alpha=0.1)\nridge_poly.fit(x_train_pr, y_train)\n\ny_test_pred_poly = ridge_poly.predict(x_test_pr)\n\nr2_ridge_poly = r2_score(y_test, y_test_pred_poly)\nrmse_ridge_poly = mean_squared_error(y_test, y_test_pred_poly, squared=False)\n\nprint(f\"R^2 (Ridge + polynomial features, test set): {r2_ridge_poly:.3f}\")\nprint(f\"RMSE (Ridge + polynomial features, test set): {rmse_ridge_poly:,.0f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusions\n\n- We explored key drivers of house prices in King County, such as square footage, grade, and waterfront.\n- A simple linear regression on `sqft_living` provides a baseline model.\n- A multivariate model with several features significantly improves the R\u00b2 score.\n- Polynomial features combined with scaling and regularization (Ridge) can further improve performance while controlling overfitting.\n\nThis notebook is designed to be easy to run for visitors to the GitHub repository: it can download the dataset automatically if it is not already present locally."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python",
   "display_name": "Python (Pyodide)",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8"
  },
  "prev_pub_hash": "d815fc46ed68b49a499250a3953962815607f5e55c574dc7527a16ab5fdc5a8e"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}